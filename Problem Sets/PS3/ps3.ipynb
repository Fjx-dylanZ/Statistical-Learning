{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>episode_name</th>\n",
       "      <th>andy</th>\n",
       "      <th>angela</th>\n",
       "      <th>darryl</th>\n",
       "      <th>dwight</th>\n",
       "      <th>jim</th>\n",
       "      <th>kelly</th>\n",
       "      <th>kevin</th>\n",
       "      <th>...</th>\n",
       "      <th>paul_lieberstein</th>\n",
       "      <th>mindy_kaling</th>\n",
       "      <th>paul_feig</th>\n",
       "      <th>gene_stupnitsky</th>\n",
       "      <th>jennifer_celotta</th>\n",
       "      <th>randall_einhorn</th>\n",
       "      <th>brent_forrester</th>\n",
       "      <th>jeffrey_blitz</th>\n",
       "      <th>justin_spitzer</th>\n",
       "      <th>imdb_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Season 1</td>\n",
       "      <td>1</td>\n",
       "      <td>pilot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Season 1</td>\n",
       "      <td>2</td>\n",
       "      <td>diversity day</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Season 1</td>\n",
       "      <td>5</td>\n",
       "      <td>basketball</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Season 1</td>\n",
       "      <td>6</td>\n",
       "      <td>hot girl</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Season 2</td>\n",
       "      <td>2</td>\n",
       "      <td>sexual harassment</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Season 9</td>\n",
       "      <td>4</td>\n",
       "      <td>work bus</td>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Season 9</td>\n",
       "      <td>17</td>\n",
       "      <td>farm</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Season 9</td>\n",
       "      <td>18</td>\n",
       "      <td>promos</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Season 9</td>\n",
       "      <td>21</td>\n",
       "      <td>livin dream</td>\n",
       "      <td>68</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>54</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Season 9</td>\n",
       "      <td>22</td>\n",
       "      <td>aarm</td>\n",
       "      <td>44</td>\n",
       "      <td>39</td>\n",
       "      <td>30</td>\n",
       "      <td>87</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       season  episode       episode_name  andy  angela  darryl  dwight  jim  \\\n",
       "0    Season 1        1              pilot     0       1       0      29   36   \n",
       "1    Season 1        2      diversity day     0       4       0      17   25   \n",
       "2    Season 1        5         basketball     0       3      15      25   21   \n",
       "3    Season 1        6           hot girl     0       3       0      28   55   \n",
       "4    Season 2        2  sexual harassment     0       2       9      11   16   \n",
       "..        ...      ...                ...   ...     ...     ...     ...  ...   \n",
       "110  Season 9        4           work bus    43       5      11      40   60   \n",
       "111  Season 9       17               farm     5       8       1      51    6   \n",
       "112  Season 9       18             promos    11      32      12      37   31   \n",
       "113  Season 9       21        livin dream    68      30      11      54   63   \n",
       "114  Season 9       22               aarm    44      39      30      87   89   \n",
       "\n",
       "     kelly  kevin  ...  paul_lieberstein  mindy_kaling  paul_feig  \\\n",
       "0        0      1  ...                 0             0          0   \n",
       "1        2      8  ...                 0             0          0   \n",
       "2        0      1  ...                 0             0          0   \n",
       "3        0      5  ...                 0             1          0   \n",
       "4        0      6  ...                 0             0          0   \n",
       "..     ...    ...  ...               ...           ...        ...   \n",
       "110      0     17  ...                 0             0          0   \n",
       "111      0     12  ...                 1             0          0   \n",
       "112      0      9  ...                 0             0          0   \n",
       "113      0     13  ...                 0             0          0   \n",
       "114      0     30  ...                 0             0          0   \n",
       "\n",
       "     gene_stupnitsky  jennifer_celotta  randall_einhorn  brent_forrester  \\\n",
       "0                  0                 0                0                0   \n",
       "1                  0                 0                0                0   \n",
       "2                  0                 0                0                0   \n",
       "3                  0                 0                0                0   \n",
       "4                  0                 0                0                0   \n",
       "..               ...               ...              ...              ...   \n",
       "110                0                 0                0                1   \n",
       "111                0                 0                0                0   \n",
       "112                0                 1                0                0   \n",
       "113                0                 0                0                0   \n",
       "114                0                 0                0                1   \n",
       "\n",
       "     jeffrey_blitz  justin_spitzer  imdb_rating  \n",
       "0                0               0          7.6  \n",
       "1                0               0          8.3  \n",
       "2                0               0          8.4  \n",
       "3                0               0          7.8  \n",
       "4                0               0          8.2  \n",
       "..             ...             ...          ...  \n",
       "110              0               0          7.9  \n",
       "111              0               0          7.5  \n",
       "112              0               0          8.0  \n",
       "113              1               0          8.9  \n",
       "114              0               0          9.3  \n",
       "\n",
       "[115 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"office_train.csv\")\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['season', 'episode', 'episode_name', 'andy', 'angela', 'darryl',\n",
       "       'dwight', 'jim', 'kelly', 'kevin', 'michael', 'oscar', 'pam', 'phyllis',\n",
       "       'ryan', 'toby', 'erin', 'jan', 'ken_kwapis', 'greg_daniels',\n",
       "       'b_j_novak', 'paul_lieberstein', 'mindy_kaling', 'paul_feig',\n",
       "       'gene_stupnitsky', 'jennifer_celotta', 'randall_einhorn',\n",
       "       'brent_forrester', 'jeffrey_blitz', 'justin_spitzer', 'imdb_rating'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Applying Ridge and LASSO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge and LASSO are great methods for parsing through data sets with lots of predictors to find:\n",
    "\n",
    "  1. An interpretable set of important predictors - which predictors are **signal** and which ones are just **noise**\n",
    "  2. The set of parameters that minimize expected prediction error (with all the caveats that we discussed in the previous lectures)\n",
    "  \n",
    "Where these methods really shine for purpose 1 (and purpose 2, by construction) is when the ratio of predictors to observations approaches 1.  To see this and work through an example using pre-built software, let's try to build a model that predicts IMDB ratings for episodes of the Office (the U.S. Version).  `office_train.csv` includes IMDB ratings (`imdb_rating`) for 115 episodes of the office and a number of predictors for each episode:\n",
    "\n",
    "  1. The season of the episode (1 - 9, which should be treated as an unordered categorical variable)\n",
    "  2. The number of times main characters speak in the episode (`andy` through `jan`)\n",
    "  3. The director of the episode (`ken_kwapis` through `justin_spitzer`).  There can be more than 1 director per episode, so it's not a pure categorical variable.  However, the correlation is high!\n",
    "  \n",
    "Let's use this data to build a predictive model for IMDB ratings and check our predictive accuracy on the heldout test set (`office_test.csv`).\n",
    "\n",
    "For this problem, you can restrict your search to the set of standard linear models (e.g. no interactions, no basis expansions, etc.).  If you would like to try to include more terms to improve the model, you are more than welcome to try!\n",
    "\n",
    "### Part 1 (10 pts.)\n",
    "\n",
    "Start by limiting yourself to the standard OLS model.   \n",
    "\n",
    "Find the regression coefficients that minimize the training error under squared error loss and use this model to compute the LOOCV estimate of the expected prediction error.\n",
    "\n",
    "Which predictors are important?  Which ones are not?  This can be difficult to tell from the OLS estimates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OLS\n",
    "train_predictor = train_df.drop(['episode', 'imdb_rating', 'episode_name'], axis=1)\n",
    "train_predictor['season'] = train_predictor['season'].apply(lambda _: _[-1])\n",
    "# check na\n",
    "train_predictor.astype(float).isna().any(axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictor = train_predictor.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intercept</th>\n",
       "      <th>season</th>\n",
       "      <th>andy</th>\n",
       "      <th>angela</th>\n",
       "      <th>darryl</th>\n",
       "      <th>dwight</th>\n",
       "      <th>jim</th>\n",
       "      <th>kelly</th>\n",
       "      <th>kevin</th>\n",
       "      <th>michael</th>\n",
       "      <th>...</th>\n",
       "      <th>b_j_novak</th>\n",
       "      <th>paul_lieberstein</th>\n",
       "      <th>mindy_kaling</th>\n",
       "      <th>paul_feig</th>\n",
       "      <th>gene_stupnitsky</th>\n",
       "      <th>jennifer_celotta</th>\n",
       "      <th>randall_einhorn</th>\n",
       "      <th>brent_forrester</th>\n",
       "      <th>jeffrey_blitz</th>\n",
       "      <th>justin_spitzer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     intercept  season  andy  angela  darryl  dwight   jim  kelly  kevin  \\\n",
       "0          1.0     1.0   0.0     1.0     0.0    29.0  36.0    0.0    1.0   \n",
       "1          1.0     1.0   0.0     4.0     0.0    17.0  25.0    2.0    8.0   \n",
       "2          1.0     1.0   0.0     3.0    15.0    25.0  21.0    0.0    1.0   \n",
       "3          1.0     1.0   0.0     3.0     0.0    28.0  55.0    0.0    5.0   \n",
       "4          1.0     2.0   0.0     2.0     9.0    11.0  16.0    0.0    6.0   \n",
       "..         ...     ...   ...     ...     ...     ...   ...    ...    ...   \n",
       "110        1.0     9.0  43.0     5.0    11.0    40.0  60.0    0.0   17.0   \n",
       "111        1.0     9.0   5.0     8.0     1.0    51.0   6.0    0.0   12.0   \n",
       "112        1.0     9.0  11.0    32.0    12.0    37.0  31.0    0.0    9.0   \n",
       "113        1.0     9.0  68.0    30.0    11.0    54.0  63.0    0.0   13.0   \n",
       "114        1.0     9.0  44.0    39.0    30.0    87.0  89.0    0.0   30.0   \n",
       "\n",
       "     michael  ...  b_j_novak  paul_lieberstein  mindy_kaling  paul_feig  \\\n",
       "0       81.0  ...        0.0               0.0           0.0        0.0   \n",
       "1       75.0  ...        1.0               0.0           0.0        0.0   \n",
       "2      104.0  ...        0.0               0.0           0.0        0.0   \n",
       "3      106.0  ...        0.0               0.0           1.0        0.0   \n",
       "4      100.0  ...        1.0               0.0           0.0        0.0   \n",
       "..       ...  ...        ...               ...           ...        ...   \n",
       "110      0.0  ...        0.0               0.0           0.0        0.0   \n",
       "111      0.0  ...        0.0               1.0           0.0        0.0   \n",
       "112      0.0  ...        0.0               0.0           0.0        0.0   \n",
       "113      0.0  ...        0.0               0.0           0.0        0.0   \n",
       "114      0.0  ...        0.0               0.0           0.0        0.0   \n",
       "\n",
       "     gene_stupnitsky  jennifer_celotta  randall_einhorn  brent_forrester  \\\n",
       "0                0.0               0.0              0.0              0.0   \n",
       "1                0.0               0.0              0.0              0.0   \n",
       "2                0.0               0.0              0.0              0.0   \n",
       "3                0.0               0.0              0.0              0.0   \n",
       "4                0.0               0.0              0.0              0.0   \n",
       "..               ...               ...              ...              ...   \n",
       "110              0.0               0.0              0.0              1.0   \n",
       "111              0.0               0.0              0.0              0.0   \n",
       "112              0.0               1.0              0.0              0.0   \n",
       "113              0.0               0.0              0.0              0.0   \n",
       "114              0.0               0.0              0.0              1.0   \n",
       "\n",
       "     jeffrey_blitz  justin_spitzer  \n",
       "0              0.0             0.0  \n",
       "1              0.0             0.0  \n",
       "2              0.0             0.0  \n",
       "3              0.0             0.0  \n",
       "4              0.0             0.0  \n",
       "..             ...             ...  \n",
       "110            0.0             0.0  \n",
       "111            0.0             0.0  \n",
       "112            0.0             0.0  \n",
       "113            1.0             0.0  \n",
       "114            0.0             0.0  \n",
       "\n",
       "[115 rows x 29 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictor.insert(0, 'intercept', np.ones(len(train_predictor)))\n",
    "train_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      7.6\n",
       "1      8.3\n",
       "2      8.4\n",
       "3      7.8\n",
       "4      8.2\n",
       "      ... \n",
       "110    7.9\n",
       "111    7.5\n",
       "112    8.0\n",
       "113    8.9\n",
       "114    9.3\n",
       "Name: imdb_rating, Length: 115, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train_df['imdb_rating']\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>imdb_rating</td>   <th>  R-squared:         </th> <td>   0.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.243</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.310</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 09 Feb 2022</td> <th>  Prob (F-statistic):</th>  <td>0.00170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:42:32</td>     <th>  Log-Likelihood:    </th> <td> -51.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   115</td>      <th>  AIC:               </th> <td>   160.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    86</td>      <th>  BIC:               </th> <td>   239.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    28</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>        <td>    7.4646</td> <td>    0.258</td> <td>   28.958</td> <td> 0.000</td> <td>    6.952</td> <td>    7.977</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>season</th>           <td>   -0.0207</td> <td>    0.035</td> <td>   -0.598</td> <td> 0.551</td> <td>   -0.089</td> <td>    0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>andy</th>             <td> 2.377e-05</td> <td>    0.003</td> <td>    0.007</td> <td> 0.994</td> <td>   -0.007</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>angela</th>           <td>    0.0121</td> <td>    0.007</td> <td>    1.841</td> <td> 0.069</td> <td>   -0.001</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>darryl</th>           <td>    0.0007</td> <td>    0.007</td> <td>    0.097</td> <td> 0.923</td> <td>   -0.014</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dwight</th>           <td>   -0.0028</td> <td>    0.003</td> <td>   -0.888</td> <td> 0.377</td> <td>   -0.009</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>jim</th>              <td>    0.0055</td> <td>    0.003</td> <td>    1.783</td> <td> 0.078</td> <td>   -0.001</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kelly</th>            <td>   -0.0169</td> <td>    0.009</td> <td>   -1.904</td> <td> 0.060</td> <td>   -0.034</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kevin</th>            <td>   -0.0058</td> <td>    0.009</td> <td>   -0.614</td> <td> 0.541</td> <td>   -0.025</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>michael</th>          <td>    0.0044</td> <td>    0.002</td> <td>    2.687</td> <td> 0.009</td> <td>    0.001</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>oscar</th>            <td>    0.0048</td> <td>    0.008</td> <td>    0.605</td> <td> 0.547</td> <td>   -0.011</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pam</th>              <td>    0.0015</td> <td>    0.003</td> <td>    0.428</td> <td> 0.670</td> <td>   -0.005</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>phyllis</th>          <td>    0.0110</td> <td>    0.009</td> <td>    1.184</td> <td> 0.239</td> <td>   -0.007</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ryan</th>             <td>   -0.0042</td> <td>    0.007</td> <td>   -0.644</td> <td> 0.522</td> <td>   -0.017</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>toby</th>             <td>   -0.0007</td> <td>    0.006</td> <td>   -0.105</td> <td> 0.917</td> <td>   -0.013</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>erin</th>             <td>    0.0044</td> <td>    0.007</td> <td>    0.647</td> <td> 0.519</td> <td>   -0.009</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>jan</th>              <td>    0.0038</td> <td>    0.004</td> <td>    0.978</td> <td> 0.331</td> <td>   -0.004</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ken_kwapis</th>       <td>   -0.0341</td> <td>    0.162</td> <td>   -0.211</td> <td> 0.834</td> <td>   -0.356</td> <td>    0.287</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>greg_daniels</th>     <td>    0.4987</td> <td>    0.147</td> <td>    3.386</td> <td> 0.001</td> <td>    0.206</td> <td>    0.792</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>b_j_novak</th>        <td>    0.4735</td> <td>    0.161</td> <td>    2.937</td> <td> 0.004</td> <td>    0.153</td> <td>    0.794</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>paul_lieberstein</th> <td>    0.4808</td> <td>    0.156</td> <td>    3.082</td> <td> 0.003</td> <td>    0.171</td> <td>    0.791</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mindy_kaling</th>     <td>    0.4021</td> <td>    0.167</td> <td>    2.402</td> <td> 0.018</td> <td>    0.069</td> <td>    0.735</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>paul_feig</th>        <td>    0.1442</td> <td>    0.154</td> <td>    0.934</td> <td> 0.353</td> <td>   -0.163</td> <td>    0.451</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gene_stupnitsky</th>  <td>    0.3680</td> <td>    0.156</td> <td>    2.361</td> <td> 0.020</td> <td>    0.058</td> <td>    0.678</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>jennifer_celotta</th> <td>    0.2065</td> <td>    0.178</td> <td>    1.160</td> <td> 0.249</td> <td>   -0.147</td> <td>    0.560</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>randall_einhorn</th>  <td>    0.0085</td> <td>    0.165</td> <td>    0.052</td> <td> 0.959</td> <td>   -0.319</td> <td>    0.336</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>brent_forrester</th>  <td>    0.4644</td> <td>    0.182</td> <td>    2.546</td> <td> 0.013</td> <td>    0.102</td> <td>    0.827</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>jeffrey_blitz</th>    <td>    0.3813</td> <td>    0.186</td> <td>    2.053</td> <td> 0.043</td> <td>    0.012</td> <td>    0.750</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>justin_spitzer</th>   <td>    0.3065</td> <td>    0.180</td> <td>    1.699</td> <td> 0.093</td> <td>   -0.052</td> <td>    0.665</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.905</td> <th>  Durbin-Watson:     </th> <td>   1.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.386</td> <th>  Jarque-Bera (JB):  </th> <td>   1.433</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.120</td> <th>  Prob(JB):          </th> <td>   0.488</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.491</td> <th>  Cond. No.          </th> <td>    880.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            imdb_rating   R-squared:                       0.429\n",
       "Model:                            OLS   Adj. R-squared:                  0.243\n",
       "Method:                 Least Squares   F-statistic:                     2.310\n",
       "Date:                Wed, 09 Feb 2022   Prob (F-statistic):            0.00170\n",
       "Time:                        20:42:32   Log-Likelihood:                -51.008\n",
       "No. Observations:                 115   AIC:                             160.0\n",
       "Df Residuals:                      86   BIC:                             239.6\n",
       "Df Model:                          28                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "intercept            7.4646      0.258     28.958      0.000       6.952       7.977\n",
       "season              -0.0207      0.035     -0.598      0.551      -0.089       0.048\n",
       "andy              2.377e-05      0.003      0.007      0.994      -0.007       0.007\n",
       "angela               0.0121      0.007      1.841      0.069      -0.001       0.025\n",
       "darryl               0.0007      0.007      0.097      0.923      -0.014       0.015\n",
       "dwight              -0.0028      0.003     -0.888      0.377      -0.009       0.003\n",
       "jim                  0.0055      0.003      1.783      0.078      -0.001       0.012\n",
       "kelly               -0.0169      0.009     -1.904      0.060      -0.034       0.001\n",
       "kevin               -0.0058      0.009     -0.614      0.541      -0.025       0.013\n",
       "michael              0.0044      0.002      2.687      0.009       0.001       0.008\n",
       "oscar                0.0048      0.008      0.605      0.547      -0.011       0.021\n",
       "pam                  0.0015      0.003      0.428      0.670      -0.005       0.008\n",
       "phyllis              0.0110      0.009      1.184      0.239      -0.007       0.029\n",
       "ryan                -0.0042      0.007     -0.644      0.522      -0.017       0.009\n",
       "toby                -0.0007      0.006     -0.105      0.917      -0.013       0.012\n",
       "erin                 0.0044      0.007      0.647      0.519      -0.009       0.018\n",
       "jan                  0.0038      0.004      0.978      0.331      -0.004       0.011\n",
       "ken_kwapis          -0.0341      0.162     -0.211      0.834      -0.356       0.287\n",
       "greg_daniels         0.4987      0.147      3.386      0.001       0.206       0.792\n",
       "b_j_novak            0.4735      0.161      2.937      0.004       0.153       0.794\n",
       "paul_lieberstein     0.4808      0.156      3.082      0.003       0.171       0.791\n",
       "mindy_kaling         0.4021      0.167      2.402      0.018       0.069       0.735\n",
       "paul_feig            0.1442      0.154      0.934      0.353      -0.163       0.451\n",
       "gene_stupnitsky      0.3680      0.156      2.361      0.020       0.058       0.678\n",
       "jennifer_celotta     0.2065      0.178      1.160      0.249      -0.147       0.560\n",
       "randall_einhorn      0.0085      0.165      0.052      0.959      -0.319       0.336\n",
       "brent_forrester      0.4644      0.182      2.546      0.013       0.102       0.827\n",
       "jeffrey_blitz        0.3813      0.186      2.053      0.043       0.012       0.750\n",
       "justin_spitzer       0.3065      0.180      1.699      0.093      -0.052       0.665\n",
       "==============================================================================\n",
       "Omnibus:                        1.905   Durbin-Watson:                   1.688\n",
       "Prob(Omnibus):                  0.386   Jarque-Bera (JB):                1.433\n",
       "Skew:                           0.120   Prob(JB):                        0.488\n",
       "Kurtosis:                       3.491   Cond. No.                         880.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols_reg = sm.OLS(endog=train_y, exog=train_predictor)\n",
    "ols_reg_result = ols_reg.fit()\n",
    "ols_reg_result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LOOCV estimate is 0.25489198976118527\n"
     ]
    }
   ],
   "source": [
    "# loocv\n",
    "nobvs = len(train_df)\n",
    "train_y_predict = ols_reg_result.predict(train_predictor)\n",
    "hat_diag = ols_reg_result.get_influence().summary_frame()['hat_diag']\n",
    "\n",
    "loocv_estimate = 1/nobvs * np.sum(\n",
    "    ((train_y - train_y_predict)/(np.ones(nobvs) - hat_diag)) ** 2\n",
    ")\n",
    "\n",
    "print(\"The LOOCV estimate is {}\".format(loocv_estimate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that (p<0.05) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 (20 pts.)\n",
    "\n",
    "Now, consider ridge regression.  Using a pre-built implementation of ridge regression, train the model using a large number of possible values for $\\lambda$.  \n",
    "\n",
    "For each value of $\\lambda$ used, compute the L1-norm for the estimated coefficients (e.g. $\\sum |\\beta_j|$ ) and plot the value of the regression coefficients against this value - there should be a separate line for each regression coefficient. (Hint: There is a built-in method for doing this in the `glmnet` package.)  Which predictors seem to be most important?  You can see these as the one with \"non-zero\" regression coefficients when $\\lambda$ is large or the L2-norm for the estimated coefficient set is small.  If it is too difficult to see over the entire $\\lambda$ path, restrict the x variable limits to the lower part of the graph with the `xlim = c(low,high)` argument.  It may still be kind of difficult to tell from the graph - ridge regression is not known for its pretty pictures!\n",
    "\n",
    "Finally, we need to select a value of $\\lambda$ that minimizes the expected prediction error.  Using $10$-fold cross validation, find a reasonable value of $\\lambda$ that should minimize the expected prediction error.  You can choose the actual minimum or a slightly less complex model (smaller $\\lambda$ is less complex).  Defend this choice.\n",
    "\n",
    "Create a plot that demonstrates the regression coefficients for the ridge regression with your optimal choice of $\\lambda$.  Which predictors are important?  Which ones are not?  I recommend using a sideways bar plot - you can see an example construction [here](https://dk81.github.io/dkmathstats_site/rvisual-sideways-bargraph.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dlopen(/opt/homebrew/lib/python3.9/site-packages/glmnet_python/GLMnet.so, 0x0006): tried: '/opt/homebrew/lib/python3.9/site-packages/glmnet_python/GLMnet.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e')), '/usr/local/lib/GLMnet.so' (no such file), '/usr/lib/GLMnet.so' (no such file)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vw/fhlnd7k958g99z5bj0yg57vh0000gn/T/ipykernel_97251/2336755410.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mglmnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglmnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m ridge_reg = glmnet(x = train_predictor.to_numpy(), y = train_y.to_numpy(), family = \"gaussian\", \n\u001b[0m\u001b[1;32m      5\u001b[0m                     \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 )\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/glmnet_python/glmnet.py\u001b[0m in \u001b[0;36mglmnet\u001b[0;34m(x, y, family, **options)\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfamily\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'gaussian'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;31m# call elnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         fit = elnet(x, is_sparse, irs, pcs, y, weights, offset, gtype, parm, \n\u001b[0m\u001b[1;32m    449\u001b[0m                     \u001b[0mlempty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnvars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mne\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mulam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                     thresh, isd, intr, maxit, family)\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/glmnet_python/elnet.py\u001b[0m in \u001b[0;36melnet\u001b[0;34m(x, is_sparse, irs, pcs, y, weights, offset, gtype, parm, lempty, nvars, jd, vp, cl, ne, nx, nlam, flmin, ulam, thresh, isd, intr, maxit, family)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# load shared fortran library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mglmlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadGlmLib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# pre-process data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/glmnet_python/loadGlmLib.py\u001b[0m in \u001b[0;36mloadGlmLib\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloadGlmLib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'posix'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mglmlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglmnet_so\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglmlib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nt'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.9/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ctypes/__init__.py\u001b[0m in \u001b[0;36mLoadLibrary\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dlltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0m__class_getitem__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenericAlias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.9/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: dlopen(/opt/homebrew/lib/python3.9/site-packages/glmnet_python/GLMnet.so, 0x0006): tried: '/opt/homebrew/lib/python3.9/site-packages/glmnet_python/GLMnet.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e')), '/usr/local/lib/GLMnet.so' (no such file), '/usr/lib/GLMnet.so' (no such file)"
     ]
    }
   ],
   "source": [
    "import glmnet_python\n",
    "from glmnet import glmnet\n",
    "\n",
    "ridge_reg = glmnet(x = train_predictor.to_numpy(), y = train_y.to_numpy(), family = \"gaussian\", \n",
    "                    alpha = 0\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
