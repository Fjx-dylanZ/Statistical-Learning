---
title: "Problem Set #3"
author: "Student: Fanjiaxuan Zhang; Prof: Kevin McAlister"
date: "February 12th, 2022"
output:
  prettydoc::html_pretty:
    df_print: kable
    theme: leonids
    highlight: github
    toc: no
    toc_depth: 2
    toc_float:
      collapsed: no
urlcolor: blue
---

```{r, include=FALSE}
library(ggplot2)
library(data.table)
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning = FALSE, fig.width = 16/2, fig.height = 9/2, tidy.opts=list(width.cutoff=60), tidy=TRUE)
```


### Part 2 (20 pts.)

Now, consider ridge regression. Using a pre-built implementation of ridge regression, train the model using a large number of possible values for $\lambda$.

For each value of $\lambda$ used, compute the L1-norm for the estimated coefficients (e.g. $\sum |\beta_j|$ ) and plot the value of the regression coefficients against this value - there should be a separate line for each regression coefficient. (Hint: There is a built-in method for doing this in the `glmnet` package.) Which predictors seem to be most important? You can see these as the one with "non-zero" regression coefficients when $\lambda$ is large or the L2-norm for the estimated coefficient set is small. If it is too difficult to see over the entire $\lambda$ path, restrict the x variable limits to the lower part of the graph with the `xlim = c(low,high)` argument. It may still be kind of difficult to tell from the graph - ridge regression is not known for its pretty pictures!

Finally, we need to select a value of $\lambda$ that minimizes the expected prediction error. Using $10$-fold cross validation, find a reasonable value of $\lambda$ that should minimize the expected prediction error. You can choose the actual minimum or a slightly less complex model (smaller $\lambda$ is less complex). Defend this choice.

Create a plot that demonstrates the regression coefficients for the ridge regression with your optimal choice of $\lambda$. Which predictors are important? Which ones are not? I recommend using a sideways bar plot - you can see an example construction [here](https://dk81.github.io/dkmathstats_site/rvisual-sideways-bargraph.html).

```{r}
library(glmnet)
library(tidyverse)
```

```{r}
library(reticulate)
use_virtualenv("~/rPyEnv")

```

```{python}
import pandas as pd
import numpy as np

train_df = pd.read_csv("office_train.csv")
train_predictor = train_df.drop(['episode', 'imdb_rating', 'episode_name'], axis=1)
train_predictor['season'] = train_predictor['season'].apply(lambda _: _[-1])
train_predictor['season'] = train_predictor['season'].astype(float)
train_y = train_df['imdb_rating']
```

```{r}
ridge_cv = glmnet::cv.glmnet(x=data.matrix(py$train_predictor), 
                  y=data.matrix(py$train_y), type.measure = 'mse', nfolds = 10,
                  family = 'gaussian',
                  alpha = 0,
                  intercept = TRUE
                  )
ridge_cv

plot(ridge_cv)
```

In this case, we choose the optimal lambda value from 10-fold cross validation that minimizes the expected MSE. I did not choose the lambda value that is one standard deviation away from the expected optimal value because the value seemed to be very unstable compared to the expected optimum. Based on several trials, the said value will either very close or very far from the optimum.

```{r}
library(tidyverse)
library(forcats)
print(paste0('Choose the lambda: ', ridge_cv$lambda.min))
ridge_reg = glmnet::glmnet(x=data.matrix(py$train_predictor), 
                  y=data.matrix(py$train_y), type.measure = 'mse',
                  family = 'gaussian',
                  alpha = 0,
                  intercept = TRUE,
                  lambda = ridge_cv$lambda.min #use the optimal lambda from cv
                  )

ridge_beta_df = cbind(variable = rownames(as.data.frame(as.matrix(ridge_reg$beta))), as.data.frame(as.matrix(ridge_reg$beta)))
rownames(ridge_beta_df) = 1:nrow(ridge_beta_df)

ridge_beta_df %>%
  rename(beta = s0) %>%
  mutate(variable = fct_reorder(variable, abs(beta))) %>%
  ggplot(aes(x=beta, y=variable)) +
  geom_col(aes(fill = abs(beta))) +
  theme_bw()
  
```

Based on the graph, `grad_daniels`, `paul_feig`, `gene_stupnitsky`, `paul_lieberstein`, and `brent_forrester` are the top five features that have the largest coefficients despite the regularization term that aims to reduce the sum of the coefficients. Therefore, based on the result from this lambda from 10fold cv and the corresponding ridge regression, these variables are the top five most important predictors.

### Part 3 (20 pts.)

Finally, consider linear regression with the LASSO penalty. Using a pre-built implementation, train the model using a large number of possible values for $\lambda$.

For each value of $\lambda$ used, compute the L1-norm for the estimated coefficients (e.g. $\sum |\beta_j|$ ) and plot the value of the regression coefficients against this value - there should be a separate line for each regression coefficient. Which predictors seem to be most important? You can see these as the one with non-zero regression coefficients when $\lambda$ is large or the L1-norm for the estimated coefficient set is small.

Finally, we need to select a value of $\lambda$ that minimizes the expected prediction error. Using $10$-fold cross validation, find a reasonable value of $\lambda$ that should minimize the expected prediction error. You can choose the actual minimum or a slightly less complex model (smaller $\lambda$ is less complex). Defend this choice.

Create a plot that demonstrates the regression coefficients for the LASSO regression with your optimal choice of $\lambda$. Which predictors are important? Which ones are not?

```{r}
lasso_reg = glmnet::glmnet(x=data.matrix(py$train_predictor), 
                  y=data.matrix(py$train_y), type.measure = 'mse',
                  family = 'gaussian',
                  alpha = 1,
                  intercept = TRUE
                  )
plot(lasso_reg)
```

```{r}
lasso_reg_betas = as.matrix(lasso_reg$beta)
lasso_reg_lambdas = lasso_reg$lambda
```

```{python}
lasso_l1_df = pd.DataFrame(columns=['lambda', 'l1_norm'])
for i in range(r.lasso_reg_betas.shape[1]):
  lasso_l1_df = lasso_l1_df.append({'lambda': r.lasso_reg_lambdas[i]
                      , 'l1_norm': sum(np.abs(r.lasso_reg_betas.transpose()[i,:])
                      )}, ignore_index=True)
lasso_l1_df
```

```{r}
plot(lasso_reg, xvar = 'lambda', label = TRUE)
```

```{python}
lasso_betas = r.lasso_reg_betas
lasso_lambdas = r.lasso_reg_lambdas

lasso_lambdaBeta_df = pd.DataFrame(columns=['lambda', 'beta'])
for i in range(lasso_betas.shape[1]):
  lasso_lambdaBeta_df = lasso_lambdaBeta_df.append(
      {'lambda': lasso_lambdas[i],
       'beta': {"beta"+str(j):lasso_betas.T[i, :][j] for j in range(lasso_betas.shape[0])}},
      ignore_index=True
  )
lasso_lambdaBeta_df = pd.merge(
    lasso_lambdaBeta_df, 
    pd.json_normalize(lasso_lambdaBeta_df['beta']), 
    left_index=True, right_index=True).drop(['beta'], axis = 1)
lasso_lambdaBeta_df = lasso_lambdaBeta_df.rename(columns={
    "beta"+str(i):train_predictor.columns[i] for i in range(lasso_betas.shape[0])
})

lasso_lambdaBeta_df
```

```{python, echo=FALSE}
import matplotlib.pyplot as plt
fig, axs = plt.subplots(1, 2, figsize = (20,17))

ax = axs[0]
for col in train_predictor.columns:
  if col == 'lambda': pass
  x = np.log(lasso_lambdaBeta_df['lambda'])
  y = lasso_lambdaBeta_df[col]
  ax.plot(x, y, '--', label=col)
  ax.text(x[len(x)-1], y[len(x) - 1], col)
ax.set_xlabel('log lambda')
ax.set_ylabel('beta')

ax = axs[1]
for col in train_predictor.columns:
  if col == 'lambda': continue
  x = np.log(lasso_lambdaBeta_df['lambda'])
  y = lasso_lambdaBeta_df[col]
  ax.plot(x, y, '--', label=col)
  if y[len(x)-50] < 0.1: continue # lambda threshold
  ax.text(x[len(x)-50], y[len(x)-50], col)
ax.set_xlabel('log lambda')
ax.set_ylabel('beta')
ax.set_xlim(left=-5, right=-2)
#ax.set_ylim(bottom = -0.02, top=0.05)
plt.show(fig)
```



```{python}
# rank beta at a large lambda (20th largest lambda)
lasso_lambdaBeta_df.iloc[20,:].T[1:].apply(lambda beta: np.abs(beta)).sort_values(ascending=False)
```

Based on the above table and graph, we can say that `greg_daniels`, `paul_lieberstein`, `gene_stupnitsky` are the most important predictors.

```{r}
lasso_cv = glmnet::cv.glmnet(x=data.matrix(py$train_predictor), 
                  y=data.matrix(py$train_y), type.measure = 'mse', nfolds = 10,
                  family = 'gaussian',
                  alpha = 1,
                  intercept = TRUE
                  )
lasso_cv

plot(lasso_cv)

```

```{r}
print(paste0('Choose the lambda: ', lasso_cv$lambda.min))
lasso_reg_opt = glmnet::glmnet(x=data.matrix(py$train_predictor), 
                  y=data.matrix(py$train_y), type.measure = 'mse',
                  family = 'gaussian',
                  alpha = 0,
                  intercept = TRUE,
                  lambda = lasso_cv$lambda.min
                  )

lassoOpt_beta_df = cbind(variable = rownames(as.data.frame(as.matrix(lasso_reg_opt$beta))), as.data.frame(as.matrix(lasso_reg_opt$beta)))
rownames(lassoOpt_beta_df) = 1:nrow(lassoOpt_beta_df)

lassoOpt_beta_df %>%
  rename(beta = s0) %>%
  mutate(variable = fct_reorder(variable, abs(beta))) %>%
  ggplot(aes(x=beta, y=variable)) +
  geom_col(aes(fill = abs(beta))) +
  theme_bw()


```

Similarly, we choose the optimal lambda value we obtained from the 10-fold cv. I choose this over another suggested lambda value (1-sd away) because the optimum seems to be more stable and reproducible. Therefore, based on this lambda value, the corresponding LASSO regression's top-five regression coefficients are `greg_daniels`, `paul_lieberstein`, `b_j_novak`, `brent_forrester`, `gene_stupnitsky`. This may tell us that directors could be the most important predictors for episode imdb score prediction.

### Part 4 (20 pts.)

Which of OLS, Ridge, or LASSO has the smallest cross validation estimate of expected prediction error? Do you have any intuition as to why this result occurs?

Using the optimal models from each step, compute an estimate of the expected prediction error using the heldout test data. Does the same relationship hold?

Create a plot (or set of plots) that puts the predicted test set outcome for each method along the x-axis and the true value on the y-axis. How does OLS compare to Ridge and LASSO? How do the regularized models improve the predictive fit?

Do any of the models provide what you might consider to be a "good" predictive model? Interpretable?

```{python}
# re-train OLS
import statsmodels.api as sm
train_predictor.insert(0, 'intercept', np.ones(len(train_predictor)))
ols_reg = sm.OLS(endog=train_y, exog=train_predictor)
# drop
train_predictor = train_predictor.drop(['intercept'], axis = 1)
```

```{python}
def get_MSE(y_true, y_pred):
    return np.mean((y_true - y_pred) ** 2)

test_df = pd.read_csv('office_train.csv')
test_predictor = test_df.drop(['episode', 'imdb_rating', 'episode_name'], axis=1)
test_predictor['season'] = test_predictor['season'].apply(lambda _: _[-1])
test_predictor['season'] = test_predictor['season'].astype(float)
test_y = test_df['imdb_rating']


#### OLS ####

test_predictor.insert(0, 'intercept', np.ones(len(train_predictor)))
test_pred = ols_reg.fit().predict(test_predictor)
print(f'OLS, Test set MSE: {get_MSE(test_y, test_pred)}')
test_predictor = test_predictor.drop(['intercept'], axis = 1)
```

```{r}
#### RIDGE ####
test_pred_ridge = glmnet::predict.glmnet(ridge_reg, data.matrix(py$test_predictor))
#### LASSO ####
test_pred_lasso = glmnet::predict.glmnet(lasso_reg_opt, data.matrix(py$test_predictor))
```

```{python}
print(f'Ridge, Test set MSE: {get_MSE(r.test_pred_ridge.ravel(), test_pred)}')
print(f'Lasso, Test set MSE: {get_MSE(r.test_pred_lasso.ravel(), test_pred)}')
```

```{python}


fig, ax = plt.subplots(1, 3, figsize = (20,10),sharex=True, sharey=True)
#OLS
ax[0].scatter(test_pred, test_df['imdb_rating'], c='red')
ax[0].set_title("OLS, predicted vs true")
ax[0].set_xlabel('OLS predicted')
ax[0].set_ylabel('True')
#Ridge
ax[1].scatter(r.test_pred_ridge, test_df['imdb_rating'], c='red')
ax[1].set_title("Ridge, predicted vs true")
ax[1].set_xlabel('Ridge predicted')

#Lasso
ax[2].scatter(r.test_pred_lasso, test_df['imdb_rating'], c='red')
ax[2].set_title("Lasso, predicted vs true")
ax[2].set_xlabel('Lasso predicted')

plt.show()


```

Based on the predictions on the test set, LASSO has the smallest MSE and the base OLS has the largest.
We can see from the graph above that OLS and LASSO has similar graphs, and Ridge regression gives us an prediction result that has less variance in their predicted values.

I think LASSO is the best model among the three because the ceoff's its out of the sample MSE based on the test set is the smallest, and it has many coeffs that are penalized to zero, which could enable us for more easier variable interpretation.

